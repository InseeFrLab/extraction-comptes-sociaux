{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "import os\n",
    "import mlflow\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import vgg19, vgg19_bn, VGG19_Weights, VGG19_BN_Weights\n",
    "\n",
    "class TableNetModule(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Pytorch Lightning Module for TableNet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: Union[optim.SGD, optim.Adam],\n",
    "        optimizer_params: Dict,\n",
    "        scheduler: Union[\n",
    "            optim.lr_scheduler.OneCycleLR, optim.lr_scheduler.ReduceLROnPlateau\n",
    "        ],\n",
    "        scheduler_params: Dict,\n",
    "        scheduler_interval: str,\n",
    "        num_class: int = 1,\n",
    "        batch_norm: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize TableNet Module.\n",
    "\n",
    "        Args:\n",
    "            optimizer\n",
    "            optimizer_params\n",
    "            scheduler\n",
    "            scheduler_params\n",
    "            scheduler_interval (str):\n",
    "            num_class (int): Number of classes per point.\n",
    "            batch_norm (bool): Select VGG with or without batch normalization.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = TableNet(num_class, batch_norm)\n",
    "        self.num_class = num_class\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer_params = optimizer_params\n",
    "        self.scheduler = scheduler\n",
    "        self.scheduler_params = scheduler_params\n",
    "        self.scheduler_interval = scheduler_interval\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Perform forward-pass.\n",
    "\n",
    "        Args:\n",
    "            batch (tensor): Batch of images to perform forward-pass.\n",
    "\n",
    "        Returns (Tuple[tensor, tensor]): Table, Column prediction.\n",
    "        \"\"\"\n",
    "        return self.model(batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "\n",
    "        Args:\n",
    "            batch (List[Tensor]): Data for training.\n",
    "            batch_idx (int): batch index.\n",
    "\n",
    "        Returns: Tensor\n",
    "        \"\"\"\n",
    "        samples, labels_table, labels_column = batch\n",
    "        output_table, output_column = self.forward(samples)\n",
    "\n",
    "        loss_table = self.dice_loss(output_table, labels_table)\n",
    "        loss_column = self.dice_loss(output_column, labels_column)\n",
    "\n",
    "        return loss_table + loss_column\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step.\n",
    "\n",
    "        Args:\n",
    "            batch (List[Tensor]): Data for training.\n",
    "            batch_idx (int): batch index.\n",
    "\n",
    "        Returns: Tensor\n",
    "        \"\"\"\n",
    "        samples, labels_table, labels_column = batch\n",
    "        output_table, output_column = self.forward(samples)\n",
    "\n",
    "        loss_table = self.dice_loss(output_table, labels_table)\n",
    "        loss_column = self.dice_loss(output_column, labels_column)\n",
    "\n",
    "        return loss_table + loss_column\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Test step.\n",
    "\n",
    "        Args:\n",
    "            batch (List[Tensor]): Data for training.\n",
    "            batch_idx (int): batch index.\n",
    "\n",
    "        Returns: Tensor\n",
    "        \"\"\"\n",
    "        samples, labels_table, labels_column = batch\n",
    "        output_table, output_column = self.forward(samples)\n",
    "\n",
    "        loss_table = self.dice_loss(output_table, labels_table)\n",
    "        loss_column = self.dice_loss(output_column, labels_column)\n",
    "\n",
    "        return loss_table + loss_column\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure optimizer for pytorch lighting.\n",
    "\n",
    "        Returns: optimizer and scheduler for pytorch lighting.\n",
    "\n",
    "        \"\"\"\n",
    "        optimizer = self.optimizer(self.parameters(), **self.optimizer_params)\n",
    "        scheduler = self.scheduler(optimizer, **self.scheduler_params)\n",
    "        scheduler = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"validation_loss\",\n",
    "            \"interval\": self.scheduler_interval,\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TableNet(nn.Module):\n",
    "    \"\"\"\n",
    "    TableNet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_class: int, batch_norm: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize TableNet.\n",
    "\n",
    "        Args:\n",
    "            num_class (int): Number of classes per point.\n",
    "            batch_norm (bool): Select VGG with or without batch normalization.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.vgg = (\n",
    "            vgg19(weights=VGG19_Weights.DEFAULT).features\n",
    "            if not batch_norm\n",
    "            else vgg19_bn(weights=VGG19_BN_Weights.DEFAULT).features\n",
    "        )\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.feature_maps_ids = [18, 27] if not batch_norm else [26, 39]\n",
    "        self.table_decoder = TableDecoder(num_class)\n",
    "        self.column_decoder = ColumnDecoder(num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Batch of images to perform forward-pass.\n",
    "\n",
    "        Returns (Tuple[torch.Tensor, torch.Tensor]): Table, Column prediction.\n",
    "        \"\"\"\n",
    "        feature_maps = []\n",
    "        with torch.no_grad():\n",
    "            for i, layer in enumerate(self.vgg):\n",
    "                x = layer(x)\n",
    "                if i in self.feature_maps_ids:\n",
    "                    feature_maps.append(x)\n",
    "\n",
    "        x_table = self.table_decoder(x, feature_maps)\n",
    "        table_output = torch.sigmoid(x_table)\n",
    "\n",
    "        x_column = self.column_decoder(x, feature_maps)\n",
    "        column_output = torch.sigmoid(x_column)\n",
    "        return table_output, column_output\n",
    "\n",
    "\n",
    "class ColumnDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Column Decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"\n",
    "        Initialize Column Decoder.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes per point.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.layer = nn.ConvTranspose2d(\n",
    "            1280, num_classes, kernel_size=2, stride=2, dilation=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x, pools):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Batch of images to perform forward-pass.\n",
    "            pools (Tuple[tensor, tensor]): The 3 and 4 pooling layer\n",
    "                from VGG-19.\n",
    "\n",
    "        Returns (tensor): Forward-pass result tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        pool_3, pool_4 = pools\n",
    "        x = self.decoder(x)\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat([x, pool_4], dim=1)\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat([x, pool_3], dim=1)\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class TableDecoder(ColumnDecoder):\n",
    "    \"\"\"\n",
    "    Table Decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize Table decoder.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes per point.\n",
    "        \"\"\"\n",
    "        super().__init__(num_classes)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ColumnDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Column Decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"\n",
    "        Initialize Column Decoder.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes per point.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.layer = nn.ConvTranspose2d(\n",
    "            64, num_classes, kernel_size=2, stride=2, dilation=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x, pools):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Batch of images to perform forward-pass.\n",
    "            pools (Tuple[tensor, tensor]): The 3 and 4 pooling layer\n",
    "                from VGG-19.\n",
    "\n",
    "        Returns (tensor): Forward-pass result tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        pool_3, pool_4 = pools\n",
    "        x = self.decoder(x)\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat([x, pool_4], dim=1)\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = self.conv_1(x)\n",
    "        x = torch.cat([x, pool_3], dim=1)\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = self.conv_2(x)\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class TableDecoder(ColumnDecoder):\n",
    "    \"\"\"\n",
    "    Table Decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize Table decoder.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes per point.\n",
    "        \"\"\"\n",
    "        super().__init__(num_classes)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Dice loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Dice Loss.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \"\"\"\n",
    "        Calculate loss.\n",
    "\n",
    "        Args:\n",
    "            inputs (tensor): Output from the forward pass.\n",
    "            targets (tensor): Labels.\n",
    "            smooth (float): Value to smooth the loss.\n",
    "\n",
    "        Returns (tensor): Dice loss.\n",
    "\n",
    "        \"\"\"\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.0 * intersection + smooth) / (\n",
    "            inputs.sum() + targets.sum() + smooth\n",
    "        )\n",
    "\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | model     | TableNet | 20.8 M\n",
      "1 | dice_loss | DiceLoss | 0     \n",
      "---------------------------------------\n",
      "798 K     Trainable params\n",
      "20.0 M    Non-trainable params\n",
      "20.8 M    Total params\n",
      "83.290    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158fcc409dbd4b8aa09d82e45df83a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "`.test(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured to save the best model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 141\u001b[0m\n\u001b[1;32m    130\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m    131\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m     strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     precision\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m    138\u001b[0m )\n\u001b[1;32m    140\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, datamodule\u001b[39m=\u001b[39mdata_module)\n\u001b[0;32m--> 141\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(datamodule\u001b[39m=\u001b[39;49mdata_module)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:706\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    704\u001b[0m     model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    705\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 706\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    707\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    708\u001b[0m )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:746\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39m# links data to the trainer\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(model, test_dataloaders\u001b[39m=\u001b[39mdataloaders, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[0;32m--> 746\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_checkpoint_connector\u001b[39m.\u001b[39;49m_select_ckpt_path(\n\u001b[1;32m    747\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mfn, ckpt_path, model_provided\u001b[39m=\u001b[39;49mmodel_provided, model_connected\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m )\n\u001b[1;32m    749\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(model, ckpt_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[1;32m    750\u001b[0m \u001b[39m# remove the tensors from the test results\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:107\u001b[0m, in \u001b[0;36m_CheckpointConnector._select_ckpt_path\u001b[0;34m(self, state_fn, ckpt_path, model_provided, model_connected)\u001b[0m\n\u001b[1;32m    105\u001b[0m         ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path\n\u001b[1;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_ckpt_path(\n\u001b[1;32m    108\u001b[0m         state_fn,\n\u001b[1;32m    109\u001b[0m         ckpt_path,\n\u001b[1;32m    110\u001b[0m         model_provided\u001b[39m=\u001b[39;49mmodel_provided,\n\u001b[1;32m    111\u001b[0m         model_connected\u001b[39m=\u001b[39;49mmodel_connected,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m ckpt_path\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:174\u001b[0m, in \u001b[0;36m_CheckpointConnector._parse_ckpt_path\u001b[0;34m(self, state_fn, ckpt_path, model_provided, model_connected)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mfast_dev_run:\n\u001b[1;32m    170\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    171\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mYou cannot execute `.\u001b[39m\u001b[39m{\u001b[39;00mfn\u001b[39m}\u001b[39;00m\u001b[39m(ckpt_path=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)` with `fast_dev_run=True`.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    172\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Please pass an exact checkpoint path to `.\u001b[39m\u001b[39m{\u001b[39;00mfn\u001b[39m}\u001b[39;00m\u001b[39m(ckpt_path=...)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         )\n\u001b[0;32m--> 174\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`.\u001b[39m\u001b[39m{\u001b[39;00mfn\u001b[39m}\u001b[39;00m\u001b[39m(ckpt_path=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)` is set but `ModelCheckpoint` is not configured to save the best model.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[39m# load best weights\u001b[39;00m\n\u001b[1;32m    178\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mcheckpoint_callback, \u001b[39m\"\u001b[39m\u001b[39mbest_model_path\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: `.test(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured to save the best model."
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sys\n",
    "sys.path.append(\"../src/extraction/\")\n",
    "import albumentations as album\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import gc\n",
    "import mlflow\n",
    "import pytorch_lightning as pl\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from pytorch_lightning.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "\n",
    "from tablenet.marmot import MarmotDataModule\n",
    "from optimizers import optimizers\n",
    "from schedulers import schedulers\n",
    "\n",
    "\n",
    "# Parameters\n",
    "with open(\"../config/tablenet_config/tablenet_config_cycle.yaml\", \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "batch_size = config[\"batch_size\"]\n",
    "max_epochs = config[\"max_epochs\"]\n",
    "num_sanity_val_steps = config[\"num_sanity_val_steps\"]\n",
    "patience = config[\"patience\"]\n",
    "batch_norm = config[\"batch_norm\"]\n",
    "fp_data = config[\"fp_data\"]\n",
    "\n",
    "optimizer_params = config[\"optimizer_params\"]\n",
    "optimizer = optimizer_params.pop(\"optimizer\")\n",
    "optimizer = optimizers[optimizer]\n",
    "\n",
    "scheduler_params = config[\"scheduler_params\"]\n",
    "scheduler = scheduler_params.pop(\"scheduler\")\n",
    "scheduler_interval = scheduler_params.pop(\"interval\")\n",
    "scheduler = schedulers[scheduler]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "image_size = (896, 896)\n",
    "transforms_augmentation = album.Compose(\n",
    "    [\n",
    "        album.Resize(1024, 1024, always_apply=True),\n",
    "        album.RandomResizedCrop(\n",
    "            *image_size, scale=(0.7, 1.0), ratio=(0.7, 1)\n",
    "        ),\n",
    "        album.HorizontalFlip(),\n",
    "        album.VerticalFlip(),\n",
    "        album.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_preprocessing = album.Compose(\n",
    "    [\n",
    "        album.Resize(*image_size, always_apply=True),\n",
    "        album.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Data for the training pipeline\n",
    "# Clean up this code\n",
    "data_dir = \"../data/marmot_data\"\n",
    "siren_test = [\n",
    "    \"305756413\",\n",
    "    \"324084698\",\n",
    "    \"326300159\",\n",
    "    \"331154765\",\n",
    "    \"333916385\",\n",
    "    \"334303823\",\n",
    "    \"344066733\",\n",
    "    \"393525852\",\n",
    "    \"393712286\",\n",
    "    \"411787567\",\n",
    "    \"414728337\",\n",
    "    \"552065187\",\n",
    "    \"552081317\",\n",
    "    \"702012956\",\n",
    "    \"797080850\",\n",
    "]\n",
    "test_data = [\n",
    "    Path(data_dir).joinpath(siren + \".bmp\") for siren in siren_test\n",
    "]\n",
    "\n",
    "train_data = [\n",
    "    path\n",
    "    for path in (\n",
    "        list(Path(data_dir).glob(\"*.png\"))\n",
    "        + list(Path(data_dir).glob(\"*.bmp\"))\n",
    "    )\n",
    "    if path not in test_data\n",
    "]\n",
    "\n",
    "if not fp_data:\n",
    "    train_data = [path for path in train_data if len(path.name) > 13]\n",
    "\n",
    "# Data module\n",
    "data_module = MarmotDataModule(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    transforms_preprocessing=transforms_preprocessing,\n",
    "    transforms_augmentation=transforms_augmentation,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    ")  # type: ignore\n",
    "\n",
    "model = TableNetModule(\n",
    "    batch_norm=batch_norm,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"validation_loss\", mode=\"min\", patience=patience\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[lr_monitor, checkpoint_callback, early_stop_callback],\n",
    "    max_epochs=max_epochs,\n",
    "    num_sanity_val_steps=num_sanity_val_steps,\n",
    "    accumulate_grad_batches=2,\n",
    "    precision=16,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=data_module)\n",
    "trainer.test(datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
